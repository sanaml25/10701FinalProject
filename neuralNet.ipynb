{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train3.pkl\", \"rb\")\n",
    "train = pickle.load(file)\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['y']\n",
    "x = train.drop('y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def prat_lemmatize(token,tag):\n",
    "\tNoun_tags = ['NN','NNP','NNPS','NNS']\n",
    "\tVerb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "\tlemmatizer = WordNetLemmatizer()\n",
    "\tif tag in Noun_tags:\n",
    "\t\treturn lemmatizer.lemmatize(token,'n')\n",
    "\telif tag in Verb_tags:\n",
    "\t\treturn lemmatizer.lemmatize(token,'v')\n",
    "\telse:\n",
    "\t\treturn lemmatizer.lemmatize(token,'n')\n",
    "\n",
    "def preprocessing(text):\n",
    "\ttext2 = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in text]).split())\n",
    "\ttokens = [word for sent in nltk.sent_tokenize(text2) for word in nltk.word_tokenize(sent)]\n",
    "\ttokens = [word.lower() for word in tokens]\n",
    "\tstopwds = stopwords.words('english')\n",
    "\ttokens = [token for token in tokens if token not in stopwds]\n",
    "\ttokens = [word for word in tokens if len(word)>=3]\n",
    "\tstemmer = PorterStemmer()\n",
    "\ttokens = [stemmer.stem(word) for word in tokens]\n",
    "\ttagged_corpus = pos_tag(tokens)\n",
    "\tpre_proc_text =   \" \".join([prat_lemmatize(token,tag) for token,tag in tagged_corpus])\n",
    "\treturn pre_proc_text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train_preprocessed = []\n",
    "for i in x_train:\n",
    "\tx_train_preprocessed.append(preprocessing(i))\n",
    "x_test_preprocessed = []\n",
    "for i in x_test:\n",
    "\tx_test_preprocessed.append(preprocessing(i))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2), stop_words='english', max_features= 10000,strip_accents='unicode', norm='l2')\n",
    "x_train_2 = vectorizer.fit_transform(x_train_preprocessed).todense()\n",
    "x_test_2 = vectorizer.transform(x_test_preprocessed).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train.values\n",
    "x_test_2 = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26085, 11986)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "nb_classes = 6\n",
    "batch_size = 50\n",
    "nb_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              11987000  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                25050     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 306       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 12,512,856\n",
      "Trainable params: 12,512,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Deep Layer Model building in Keras\n",
    "#del model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,input_shape= (11986,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23476 samples, validate on 2609 samples\n",
      "Epoch 1/40\n",
      "23476/23476 [==============================] - 103s 4ms/step - loss: 1.9672 - accuracy: 0.3244 - val_loss: 1.6056 - val_accuracy: 0.3507\n",
      "Epoch 2/40\n",
      "23476/23476 [==============================] - 99s 4ms/step - loss: 1.5762 - accuracy: 0.3360 - val_loss: 1.5260 - val_accuracy: 0.3507\n",
      "Epoch 3/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.5339 - accuracy: 0.3360 - val_loss: 1.4937 - val_accuracy: 0.3507\n",
      "Epoch 4/40\n",
      "23476/23476 [==============================] - 105s 4ms/step - loss: 1.4993 - accuracy: 0.3358 - val_loss: 1.4444 - val_accuracy: 0.3867\n",
      "Epoch 5/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.4593 - accuracy: 0.3591 - val_loss: 1.3963 - val_accuracy: 0.3979\n",
      "Epoch 6/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.4118 - accuracy: 0.3718 - val_loss: 1.3420 - val_accuracy: 0.4028\n",
      "Epoch 7/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.3669 - accuracy: 0.3820 - val_loss: 1.2569 - val_accuracy: 0.3902\n",
      "Epoch 8/40\n",
      "23476/23476 [==============================] - 101s 4ms/step - loss: 1.3427 - accuracy: 0.3820 - val_loss: 1.2379 - val_accuracy: 0.4285\n",
      "Epoch 9/40\n",
      "23476/23476 [==============================] - 105s 4ms/step - loss: 1.3148 - accuracy: 0.3807 - val_loss: 1.2146 - val_accuracy: 0.4258\n",
      "Epoch 10/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.2730 - accuracy: 0.4081 - val_loss: 1.1672 - val_accuracy: 0.4795\n",
      "Epoch 11/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.2440 - accuracy: 0.4273 - val_loss: 1.1923 - val_accuracy: 0.4634\n",
      "Epoch 12/40\n",
      "23476/23476 [==============================] - 106s 4ms/step - loss: 1.2323 - accuracy: 0.4338 - val_loss: 1.1521 - val_accuracy: 0.4822\n",
      "Epoch 13/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.2140 - accuracy: 0.4381 - val_loss: 1.1377 - val_accuracy: 0.4887\n",
      "Epoch 14/40\n",
      "23476/23476 [==============================] - 106s 5ms/step - loss: 1.1993 - accuracy: 0.4445 - val_loss: 1.1454 - val_accuracy: 0.4887\n",
      "Epoch 15/40\n",
      "23476/23476 [==============================] - 101s 4ms/step - loss: 1.1922 - accuracy: 0.4492 - val_loss: 1.1231 - val_accuracy: 0.5029\n",
      "Epoch 16/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.1789 - accuracy: 0.4597 - val_loss: 1.1557 - val_accuracy: 0.4619\n",
      "Epoch 17/40\n",
      "23476/23476 [==============================] - 98s 4ms/step - loss: 1.1820 - accuracy: 0.4561 - val_loss: 1.1352 - val_accuracy: 0.4749\n",
      "Epoch 18/40\n",
      "23476/23476 [==============================] - 105s 4ms/step - loss: 1.1681 - accuracy: 0.4647 - val_loss: 1.1382 - val_accuracy: 0.4795\n",
      "Epoch 19/40\n",
      "23476/23476 [==============================] - 119s 5ms/step - loss: 1.1428 - accuracy: 0.4748 - val_loss: 1.1099 - val_accuracy: 0.4898\n",
      "Epoch 20/40\n",
      "23476/23476 [==============================] - 105s 4ms/step - loss: 1.1561 - accuracy: 0.4727 - val_loss: 1.1248 - val_accuracy: 0.4837\n",
      "Epoch 21/40\n",
      "23476/23476 [==============================] - 106s 5ms/step - loss: 1.1495 - accuracy: 0.4722 - val_loss: 1.1171 - val_accuracy: 0.4730\n",
      "Epoch 22/40\n",
      "23476/23476 [==============================] - 102s 4ms/step - loss: 1.1327 - accuracy: 0.4746 - val_loss: 1.1235 - val_accuracy: 0.4791\n",
      "Epoch 23/40\n",
      "23476/23476 [==============================] - 97s 4ms/step - loss: 1.1356 - accuracy: 0.4777 - val_loss: 1.1331 - val_accuracy: 0.4661\n",
      "Epoch 24/40\n",
      "23476/23476 [==============================] - 97s 4ms/step - loss: 1.1310 - accuracy: 0.4796 - val_loss: 1.1250 - val_accuracy: 0.4764\n",
      "Epoch 25/40\n",
      "23476/23476 [==============================] - 98s 4ms/step - loss: 1.1265 - accuracy: 0.4857 - val_loss: 1.1154 - val_accuracy: 0.4914\n",
      "Epoch 26/40\n",
      "23476/23476 [==============================] - 104s 4ms/step - loss: 1.1300 - accuracy: 0.4844 - val_loss: 1.1429 - val_accuracy: 0.4714\n",
      "Epoch 27/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.1234 - accuracy: 0.4910 - val_loss: 1.1208 - val_accuracy: 0.4764\n",
      "Epoch 28/40\n",
      "23476/23476 [==============================] - 103s 4ms/step - loss: 1.1167 - accuracy: 0.4930 - val_loss: 1.1254 - val_accuracy: 0.4703\n",
      "Epoch 29/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.1317 - accuracy: 0.4798 - val_loss: 1.1180 - val_accuracy: 0.4688\n",
      "Epoch 30/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.1136 - accuracy: 0.4901 - val_loss: 1.1285 - val_accuracy: 0.4684\n",
      "Epoch 31/40\n",
      "23476/23476 [==============================] - 100s 4ms/step - loss: 1.1128 - accuracy: 0.4896 - val_loss: 1.1135 - val_accuracy: 0.4722\n",
      "Epoch 32/40\n",
      "23476/23476 [==============================] - 102s 4ms/step - loss: 1.1106 - accuracy: 0.4893 - val_loss: 1.1375 - val_accuracy: 0.4404\n",
      "Epoch 33/40\n",
      "23476/23476 [==============================] - 102s 4ms/step - loss: 1.1080 - accuracy: 0.4952 - val_loss: 1.1541 - val_accuracy: 0.4243\n",
      "Epoch 34/40\n",
      "23476/23476 [==============================] - 101s 4ms/step - loss: 1.1134 - accuracy: 0.4947 - val_loss: 1.1213 - val_accuracy: 0.4768\n",
      "Epoch 35/40\n",
      "23476/23476 [==============================] - 99s 4ms/step - loss: 1.0902 - accuracy: 0.5007 - val_loss: 1.1675 - val_accuracy: 0.4220\n",
      "Epoch 36/40\n",
      "23476/23476 [==============================] - 103s 4ms/step - loss: 1.1010 - accuracy: 0.4959 - val_loss: 1.1135 - val_accuracy: 0.4626\n",
      "Epoch 37/40\n",
      "23476/23476 [==============================] - 101s 4ms/step - loss: 1.0832 - accuracy: 0.5088 - val_loss: 1.1384 - val_accuracy: 0.4500\n",
      "Epoch 38/40\n",
      "23476/23476 [==============================] - 102s 4ms/step - loss: 1.0873 - accuracy: 0.5086 - val_loss: 1.1401 - val_accuracy: 0.4442\n",
      "Epoch 39/40\n",
      "23476/23476 [==============================] - 102s 4ms/step - loss: 1.0890 - accuracy: 0.5057 - val_loss: 1.1526 - val_accuracy: 0.4327\n",
      "Epoch 40/40\n",
      "23476/23476 [==============================] - 108s 5ms/step - loss: 1.1033 - accuracy: 0.5031 - val_loss: 1.1379 - val_accuracy: 0.4557\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(x_train_2, Y_train, batch_size=batch_size, epochs=nb_epochs,verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Prediction\n",
    "y_train_predclass = model.predict_classes(x_train_2,batch_size=batch_size)\n",
    "y_test_predclass = model.predict_classes(x_test_2,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnDeep Neural Network - Train accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.473)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"nnDeep Neural Network - Train accuracy:\"),(round(accuracy_score( y_train, y_train_predclass),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDeep Neural Network - Test accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.447)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"nDeep Neural Network - Test accuracy:\"),(round(accuracy_score( y_test,y_test_predclass),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDeep Neural Network - Train Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.28      0.39      2326\n",
      "          2       0.33      0.09      0.14      2757\n",
      "          3       0.28      0.26      0.27      4057\n",
      "          4       0.42      0.77      0.54      8134\n",
      "          5       0.73      0.46      0.57      8811\n",
      "\n",
      "avg / total       0.51      0.47      0.45     26085\n",
      "\n",
      "nDeep Neural Network - Test Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.25      0.35       805\n",
      "          2       0.32      0.08      0.13       955\n",
      "          3       0.23      0.23      0.23      1271\n",
      "          4       0.41      0.73      0.53      2770\n",
      "          5       0.68      0.44      0.54      2894\n",
      "\n",
      "avg / total       0.48      0.45      0.43      8695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"nDeep Neural Network - Train Classification Report\")\n",
    "print (classification_report(y_train,y_train_predclass))\n",
    "print (\"nDeep Neural Network - Test Classification Report\")\n",
    "print (classification_report(y_test,y_test_predclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
